{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b2ea90a-ed48-4fa8-bbcc-463bbe2be8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup  \n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "import glob\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae6e6d9b-fc10-4273-ba19-b7548c295808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsetable(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    table = soup.find('table', {'class': 'wilko'})\n",
    "    rows = table.find_all('tr')\n",
    "    columnnames=[]\n",
    "    array=[]\n",
    "    for row in rows:\n",
    "        columns = row.find_all('th')\n",
    "        if columns:\n",
    "            columnnames=[column.text.strip() for column in columns]\n",
    "        \n",
    "        cells = row.find_all('td')\n",
    "        if cells:\n",
    "            array.append([cell.text.strip() for cell in cells])\n",
    "            \n",
    "    df_raw=pd.DataFrame(columns=columnnames,data=array)\n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ff9de9f-32f3-4ea5-b224-f31df2e0c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to define the types for the variables/columns\n",
    "def table_cleaner(df_raw):\n",
    "    #we throw away entries with unclear source\n",
    "    df_raw=df_raw.dropna(subset=[\"Institut\"])\n",
    "    #and we have to split the column \"Sonstige\" because sometimes it contains\n",
    "    #entries for multiple parties\n",
    "    splitted_sonstige=df_raw[\"Sonstige\"].astype(str).str.split(\"%\")\n",
    "    \n",
    "    #and we want to sort it into a dict later so we will retrieve    \n",
    "    #the keys for these multiple entries first\n",
    "    array_of_keys=[\"Sonstige_no_differentiation\"]\n",
    "    for row in range(len(splitted_sonstige)):\n",
    "        for char in splitted_sonstige.iloc[row]:\n",
    "            party_sonstige_list_results=char.split()\n",
    "            if (len(party_sonstige_list_results)>1):\n",
    "                array_of_keys.append(char.split()[0])\n",
    "           \n",
    "    #now we create a default dictionary that will be used in each row\n",
    "    default_dict=dict((k, np.nan) for k in array_of_keys)\n",
    "    #and will be pushed into an array unless\n",
    "    array_sonstige=[]\n",
    "\n",
    "    for row in range(len(splitted_sonstige)):\n",
    "        row_dict=default_dict.copy()\n",
    "        for char in splitted_sonstige.iloc[row]:\n",
    "            party_sonstige_list_results=char.split()\n",
    "            \n",
    "            #we have entries in a cell that differentiate the sonstige \n",
    "            if (len(party_sonstige_list_results)>1):\n",
    "                row_dict[party_sonstige_list_results[0]]=party_sonstige_list_results[1]\n",
    "            #or we have at least one number in the cell, this is then added as \"Sonstige_no_differentiation\"\n",
    "            if (len(party_sonstige_list_results)==1):\n",
    "                row_dict[\"Sonstige_no_differentiation\"]=party_sonstige_list_results[0]\n",
    "        #we keep on appending these dictionaries into the array        \n",
    "        array_sonstige.append(row_dict)\n",
    "        \n",
    "    #and then create a dataframe\n",
    "    sonstige_df=pd.DataFrame(array_sonstige)\n",
    "\n",
    "    #that is then added to the original dataframe\n",
    "    df_raw_sonstige=pd.concat([df_raw,sonstige_df],axis=1)\n",
    "\n",
    "    \n",
    "    df_polls=df_raw_sonstige[~df_raw_sonstige.Institut.astype(str).str.contains(\"Landtag\")]\n",
    "    df_polls[df_polls.columns[4:]]=df_polls[df_polls.columns[4:]].replace({'%': ''}, regex=True)\n",
    "    df_polls[df_polls.columns[4:]]=df_polls[df_polls.columns[4:]].replace({',': '.'}, regex=True)\n",
    "    \n",
    "    df_polls=df_polls.drop([\"Sonstige\"],axis=1)\n",
    "    SonstigeColumns=df_polls.columns[df_polls.columns.astype(str).str.contains(\"Son\")]\n",
    "    df_polls[SonstigeColumns]=df_polls[SonstigeColumns].apply(pd.to_numeric, errors='coerce')\n",
    "    sonstige_summed=df_polls[SonstigeColumns].sum(axis=1)\n",
    "    df_polls_cleaned=df_polls.drop(SonstigeColumns,axis=1)\n",
    "    df_polls_cleaned[\"Sonstige\"]=sonstige_summed\n",
    "\n",
    "    df_polls_cleaned=df_polls_cleaned.dropna(subset=[\"Befragte\"]).reset_index(drop=True)\n",
    "    befragte_liste=[]\n",
    "    for row in df_polls_cleaned[\"Befragte\"].astype(str).str.split(\"•\"):\n",
    "        befragte=(row[1].strip()[:5])\n",
    "        if \".\" in befragte:\n",
    "            befragte=befragte.replace(\".\",\"\")\n",
    "        else:\n",
    "            befragte=befragte[:4]\n",
    "        befragte_number=int(befragte)\n",
    "        befragte_liste.append(befragte_number)\n",
    "    befragte_serie=pd.Series(befragte_liste)\n",
    "    df_polls_cleaned[\"Befragte_neu\"]=befragte_serie\n",
    "    \n",
    "\n",
    "    return df_polls_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d566dfa7-4485-47c0-9d76-6d0e6bf21f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dirichet_transform(df_polls_cleaned):\n",
    "    df_polls_cleaned[df_polls_cleaned.columns[4:]] = df_polls_cleaned[df_polls_cleaned.columns[4:]].apply(pd.to_numeric, errors='coerce')\n",
    "    df_polls_cleaned[df_polls_cleaned.columns[4:]]=df_polls_cleaned[df_polls_cleaned.columns[4:]].astype(float)\n",
    "    df_polls_cleaned[\"Datum\"]=pd.to_datetime(df_polls_cleaned[\"Datum\"], format=\"%d.%m.%Y\")\n",
    "    timeperiod_of_interest=last_60_days=df_polls_cleaned.iloc[0][\"Datum\"]- timedelta(days=60)\n",
    "    results_of_interest=df_polls_cleaned[df_polls_cleaned[\"Datum\"]>timeperiod_of_interest]\n",
    "    results_of_interest=results_of_interest.dropna(axis=1, how='all')\n",
    "    \n",
    "    results_of_interest_no_zeros=results_of_interest.loc[:, ~results_of_interest.isin([0,np.nan]).all(0)]\n",
    "    only_party_results=(results_of_interest_no_zeros[results_of_interest_no_zeros.columns[4:-1]])/100\n",
    "    only_party_results_respondents=(only_party_results.T*(results_of_interest_no_zeros[\"Befragte_neu\"].values)).T\n",
    "    mean_results=only_party_results_respondents.mean()*len(only_party_results_respondents)\n",
    "    column_names=mean_results.index.tolist()\n",
    "    values_array=mean_results.values.tolist()\n",
    "    s = np.random.dirichlet((values_array), size = 100) \n",
    "    results_dirichlet=pd.DataFrame(s*100,columns=column_names)\n",
    "    results_dirichlet=results_dirichlet.round(1)\n",
    "    results_dirichlet[\"Sonstige\"]=results_dirichlet[\"Sonstige\"]+(100-results_dirichlet.sum(axis=1))\n",
    "    return results_dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d02042a8-cebe-4737-82c7-b0eb8f18f555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scenario_calc(result):\n",
    "    scenario_json={}\n",
    "    max_column=result.idxmax(axis=1)\n",
    "    winner_series=pd.Series(max_column)\n",
    "    AfDWinner=winner_series.value_counts()[\"AfD\"]-1\n",
    "    scenario_json[\"AfDGewinnt\"]=AfDWinner\n",
    "    fuenfprozent_huerde=pd.DataFrame(np.where(result<5,0,result),columns=result.columns)\n",
    "    fuenfprozent_huerde=fuenfprozent_huerde.div(fuenfprozent_huerde.sum(axis=1), axis=0)*100\n",
    "    keineMehrheitKoalition=len(fuenfprozent_huerde[fuenfprozent_huerde[current_coalitions[bundesland]].sum(axis=1)<50])\n",
    "    if (keineMehrheitKoalition==100):\n",
    "        keineMehrheitKoalition=keineMehrheitKoalition-1\n",
    "    if (keineMehrheitKoalition==0):\n",
    "        keineMehrheitKoalition=keineMehrheitKoalition+1\n",
    "    scenario_json[\"KoalitionEndet\"]=keineMehrheitKoalition\n",
    "    keineKlassischeMehrheit=len(fuenfprozent_huerde[(fuenfprozent_huerde[\"AfD\"]+fuenfprozent_huerde[\"BSW\"])>50])\n",
    "    if (keineKlassischeMehrheit==100):\n",
    "        keineKlassischeMehrheit=keineKlassischeMehrheit-1\n",
    "    if (keineKlassischeMehrheit==0):\n",
    "        keineKlassischeMehrheit=keineKlassischeMehrheit+1\n",
    "    scenario_json[\"KeineKlassischeMehrheit\"]=keineKlassischeMehrheit\n",
    "    return scenario_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7daa7e4f-7a91-4314-ba05-f07d192be3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/79cxhkf56b38c317w6g5zkr0mmx5lp/T/ipykernel_89670/1568612917.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_polls[df_polls.columns[4:]]=df_polls[df_polls.columns[4:]].replace({'%': ''}, regex=True)\n",
      "/var/folders/55/79cxhkf56b38c317w6g5zkr0mmx5lp/T/ipykernel_89670/1568612917.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_polls[df_polls.columns[4:]]=df_polls[df_polls.columns[4:]].replace({',': '.'}, regex=True)\n",
      "/var/folders/55/79cxhkf56b38c317w6g5zkr0mmx5lp/T/ipykernel_89670/1568612917.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_polls[df_polls.columns[4:]]=df_polls[df_polls.columns[4:]].replace({'%': ''}, regex=True)\n",
      "/var/folders/55/79cxhkf56b38c317w6g5zkr0mmx5lp/T/ipykernel_89670/1568612917.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_polls[df_polls.columns[4:]]=df_polls[df_polls.columns[4:]].replace({',': '.'}, regex=True)\n",
      "/var/folders/55/79cxhkf56b38c317w6g5zkr0mmx5lp/T/ipykernel_89670/1568612917.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_polls[df_polls.columns[4:]]=df_polls[df_polls.columns[4:]].replace({'%': ''}, regex=True)\n",
      "/var/folders/55/79cxhkf56b38c317w6g5zkr0mmx5lp/T/ipykernel_89670/1568612917.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_polls[df_polls.columns[4:]]=df_polls[df_polls.columns[4:]].replace({',': '.'}, regex=True)\n"
     ]
    }
   ],
   "source": [
    "current_coalitions={\"sachsen\":[\"CDU\", \"GRÜNE\", \"SPD\"], \"thueringen\":[\"LINKE\", \"GRÜNE\", \"SPD\"],\"brandenburg\":[\"CDU\", \"GRÜNE\", \"SPD\"]}\n",
    "scenarios_bundeslaender={}\n",
    "results_bundeslaender={}\n",
    "files_json=glob.glob(\"*.json\")\n",
    "\n",
    "for bundesland in current_coalitions.keys():\n",
    "    bl_table=parsetable(\"https://www.wahlrecht.de/umfragen/landtage/\"+bundesland+\".htm\")\n",
    "    df_polls_cleaned=table_cleaner(bl_table)\n",
    "    institute_name=df_polls_cleaned[\"Institut\"].iloc[0]\n",
    "    latest_date=df_polls_cleaned[\"Datum\"].astype(str).str[:10].iloc[0]\n",
    "    filename=bundesland+\"_\"+institute_name+\"-\"+latest_date\n",
    "    if (filename+\".json\") in files_json:\n",
    "        result=pd.read_json(filename+\".json\")\n",
    "    else:\n",
    "        result=dirichet_transform(df_polls_cleaned)\n",
    "        result.to_json(filename+\".json\")\n",
    "        result.to_csv(filename+\".csv\",index=False)\n",
    "    results_bundeslaender[bundesland]=result\n",
    "    scenario=scenario_calc(result)\n",
    "    scenarios_bundeslaender[bundesland]=scenario\n",
    "with open(\"outcome.json\", \"w\") as outfile: \n",
    "    json.dump(scenarios_bundeslaender, outfile,default=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c50db22-5743-4738-b586-e1ca3a600c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sachsen': {'AfDGewinnt': np.int64(50),\n",
       "  'KoalitionEndet': 99,\n",
       "  'KeineKlassischeMehrheit': 1},\n",
       " 'thueringen': {'AfDGewinnt': np.int64(99),\n",
       "  'KoalitionEndet': 99,\n",
       "  'KeineKlassischeMehrheit': 99},\n",
       " 'brandenburg': {'AfDGewinnt': np.int64(99),\n",
       "  'KoalitionEndet': 22,\n",
       "  'KeineKlassischeMehrheit': 1}}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenarios_bundeslaender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7e3ccfc-aab4-45a9-bb65-9f239d17e899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AfDGewinnt\n",
      "              0\n",
      "Sachsen      50\n",
      "Thüringen    99\n",
      "Brandenburg  99\n",
      "\n",
      "KoalitionEndet\n",
      "              0\n",
      "Sachsen      99\n",
      "Thüringen    99\n",
      "Brandenburg  22\n",
      "\n",
      "KeineKlassischeMehrheit\n",
      "              0\n",
      "Sachsen       1\n",
      "Thüringen    99\n",
      "Brandenburg   1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for scenario in scenarios_bundeslaender[\"sachsen\"]:\n",
    "    scenario_dict={}\n",
    "    print(scenario)\n",
    "\n",
    "    for bundesland in scenarios_bundeslaender.keys():\n",
    "        prob_scenario=(scenarios_bundeslaender[bundesland][scenario])\n",
    "        bundesland_name=bundesland.capitalize().replace(\"ue\",\"ü\")\n",
    "        scenario_dict[bundesland_name]=[prob_scenario]\n",
    "    scenario_df=pd.DataFrame(scenario_dict).T\n",
    "    print(scenario_df)\n",
    "    print(\"\")\n",
    "\n",
    "    scenario_df.to_csv(scenario+\".csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18798a55-0fc4-4fa7-a96d-40687359adfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDU</th>\n",
       "      <th>SPD</th>\n",
       "      <th>GRÜNE</th>\n",
       "      <th>FDP</th>\n",
       "      <th>LINKE</th>\n",
       "      <th>AfD</th>\n",
       "      <th>BVB/FW</th>\n",
       "      <th>BSW</th>\n",
       "      <th>Sonstige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.7</td>\n",
       "      <td>18.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>23.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>23.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>15.9</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.2</td>\n",
       "      <td>19.8</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>23.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.4</td>\n",
       "      <td>19.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>16.6</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.9</td>\n",
       "      <td>19.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>17.2</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>18.7</td>\n",
       "      <td>18.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>23.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>16.6</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>18.3</td>\n",
       "      <td>18.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>23.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>17.6</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>18.2</td>\n",
       "      <td>20.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>16.7</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>18.8</td>\n",
       "      <td>17.9</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>18.4</td>\n",
       "      <td>18.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>17.1</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CDU   SPD  GRÜNE  FDP  LINKE   AfD  BVB/FW   BSW  Sonstige\n",
       "0   18.7  18.9    5.8  2.7    4.7  23.3     4.3  17.0       4.6\n",
       "1   19.0  20.3    6.4  2.8    4.6  23.8     3.8  15.9       3.4\n",
       "2   18.2  19.8    6.5  2.4    4.9  23.1     4.0  16.6       4.5\n",
       "3   18.4  19.5    6.3  2.6    5.1  23.4     3.6  16.6       4.5\n",
       "4   18.9  19.3    5.5  2.4    5.0  23.7     3.6  17.2       4.4\n",
       "..   ...   ...    ...  ...    ...   ...     ...   ...       ...\n",
       "95  18.7  18.5    6.2  3.1    4.7  23.8     3.4  16.6       5.0\n",
       "96  18.3  18.4    6.9  3.3    4.6  23.3     3.2  17.6       4.4\n",
       "97  18.2  20.4    6.9  2.7    4.7  23.1     3.6  16.7       3.7\n",
       "98  18.8  17.9    6.6  2.7    5.0  24.4     3.6  17.0       4.0\n",
       "99  18.4  18.9    6.5  2.9    4.8  23.6     3.4  17.1       4.4\n",
       "\n",
       "[100 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85685bfb-d2fb-4063-94a4-9d5038dddfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sachsen', 'thueringen', 'brandenburg'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_bundeslaender.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4663b1f-4983-4edb-a4a4-3dd215bd4407",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/55/79cxhkf56b38c317w6g5zkr0mmx5lp/T/ipykernel_89670/670601920.py:4: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"median\"].loc[\"Sonstige\"]=df[\"median\"].loc[\"Sonstige\"]+missing\n",
      "/var/folders/55/79cxhkf56b38c317w6g5zkr0mmx5lp/T/ipykernel_89670/670601920.py:4: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"median\"].loc[\"Sonstige\"]=df[\"median\"].loc[\"Sonstige\"]+missing\n",
      "/var/folders/55/79cxhkf56b38c317w6g5zkr0mmx5lp/T/ipykernel_89670/670601920.py:4: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df[\"median\"].loc[\"Sonstige\"]=df[\"median\"].loc[\"Sonstige\"]+missing\n"
     ]
    }
   ],
   "source": [
    "for bundesland in results_bundeslaender.keys():\n",
    "    df=pd.DataFrame({\"max\":results_bundeslaender[bundesland].max(),\"median\":results_bundeslaender[bundesland].median(),\"min\":results_bundeslaender[bundesland].min()})\n",
    "    missing=100-df[\"median\"].sum()\n",
    "    df[\"median\"].loc[\"Sonstige\"]=df[\"median\"].loc[\"Sonstige\"]+missing\n",
    "    df.to_csv(bundesland+\"_max_min.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95195f49-3527-4c57-a3e5-becad0d889a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7503c12-84d6-445a-8f1d-4b5730b2202b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d15b392-d4c1-492b-baf1-3689a6b03861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
