{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2009de7a-e198-4876-8988-609f5cdc785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import these libraries\n",
    "import urllib.request, json , time, os, difflib, itertools\n",
    "import pandas as pd\n",
    "from multiprocessing.dummy import Pool\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4589d282-308f-4325-9116-b48cb9283b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#an check if we have a functioning internet connection\n",
    "try:\n",
    "    import httplib\n",
    "except:\n",
    "    import http.client as httplib\n",
    "\n",
    "def check_internet():\n",
    "    conn = httplib.HTTPConnection(\"www.google.com\", timeout=5)\n",
    "    try:\n",
    "        conn.request(\"HEAD\", \"/\")\n",
    "        conn.close()\n",
    "        return True\n",
    "    except:\n",
    "        conn.close()\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7d4af5c-613d-4627-98fe-290dec66837d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_internet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78c91fb7-36f8-46e0-b050-fe6856fd537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a function that is taking in the query url\n",
    "# and a path for the json and the csv to be stored\n",
    "def get_historic_price(query_url,json_path,csv_path):\n",
    "    \n",
    "    while not check_internet():\n",
    "        print(\"Could not connect, trying again in 5 seconds...\")\n",
    "        time.sleep(5)\n",
    "    #we get the stock id by retrieving it from the query url as the string between symbol= and &period \n",
    "    stock_id=query_url.split(\"&period\")[0].split(\"symbol=\")[1]\n",
    "    # if the csv already exists, we update the data simpy \n",
    "    if os.path.exists(csv_path+stock_id+'.csv') and os.stat(csv_path+stock_id+'.csv').st_size != 0:\n",
    "        print(\"<<<  Historical data of \"+stock_id+\" already exists, Updating data...\")\n",
    "\n",
    "    try:\n",
    "        with urllib.request.urlopen(query_url) as url:\n",
    "            parsed = json.loads(url.read().decode())\n",
    "    except:\n",
    "        print(\"|||  Historical data of \"+stock_id+\" doesn't exist\")\n",
    "        return\n",
    "\n",
    "    #otherwise we remove the json and add a new json dump\n",
    "    else:\n",
    "        if os.path.exists(json_path+stock_id+'.json'):\n",
    "            os.remove(json_path+stock_id+'.json')\n",
    "        with open(json_path+stock_id+'.json', 'w') as outfile:\n",
    "            json.dump(parsed, outfile, indent=4)\n",
    "\n",
    "        try:\n",
    "            Date=[]\n",
    "            #for each entry in the parsed json we restructure it into lists\n",
    "            for i in parsed['chart']['result'][0]['timestamp']:\n",
    "                Date.append(datetime.utcfromtimestamp(int(i)).strftime('%d-%m-%Y'))\n",
    "            \n",
    "            Low=parsed['chart']['result'][0]['indicators']['quote'][0]['low']\n",
    "            Open=parsed['chart']['result'][0]['indicators']['quote'][0]['open']\n",
    "            Volume=parsed['chart']['result'][0]['indicators']['quote'][0]['volume']\n",
    "            High=parsed['chart']['result'][0]['indicators']['quote'][0]['high']\n",
    "            Close=parsed['chart']['result'][0]['indicators']['quote'][0]['close']\n",
    "            Adjusted_Close=parsed['chart']['result'][0]['indicators']['adjclose'][0]['adjclose']\n",
    "\n",
    "            #that we put into an array that we write into a csv\n",
    "\n",
    "            df=pd.DataFrame(list(zip(Date,Low,Open,Volume,High,Close,Adjusted_Close)),columns =['Date','Low','Open','Volume','High','Close','Adjusted Close'])\n",
    "\n",
    "            if os.path.exists(csv_path+stock_id+'.csv'):\n",
    "                os.remove(csv_path+stock_id+'.csv')\n",
    "            df.to_csv(csv_path+stock_id+'.csv', sep=',', index=None)\n",
    "            print(\">>>  Historical data of \"+stock_id+\" saved\")\n",
    "            return\n",
    "        except:\n",
    "            print(\">>>  Historical data of \"+stock_id+\" exists but has no trading data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d711b083-e140-44c5-b28b-554b95c34b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we write the path for the folder structure which is based on different os dependent notations\n",
    "json_path = os.getcwd()+os.sep+\"..\"+os.sep+\"historic_data\"+os.sep+\"json\"+os.sep\n",
    "csv_path = os.getcwd()+os.sep+\"..\"+os.sep+\"historic_data\"+os.sep+\"csv\"+os.sep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e040d577-362c-4079-909e-65b315425983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we create directories if they do not exist\n",
    "if not os.path.isdir(json_path):\n",
    "    os.makedirs(json_path)\n",
    "if not os.path.isdir(csv_path):\n",
    "    os.makedirs(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53cf9e5b-dd29-4f1b-a8bb-e8aa7dff3006",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we define some predetermine variables\n",
    "period1 = 0\n",
    "period2 = 9999999999\n",
    "interval = \"1d\"\n",
    "country_name = \"germany\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28bbee2a-e19b-4e38-b05b-52ae1cd7b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#and our custom dictionary of dax 40 companies and their stock id\n",
    "full_ticker_dict={\n",
    "\"Adidas\":'ADS.DE',\n",
    " \"Airbus\":'AIR.PA',\n",
    " \"Allianz\":'ALV.DE',\n",
    " \"BASF\":'BAS.DE',\n",
    "\"Bayer\":'BAYN.DE',\n",
    "        \"Beiersdorf\":\"BEI.DE\",\n",
    " \"BMW\":'BMW.DE',\n",
    " \"Brenntag\":'BNR.DE',\n",
    "\"Continental\":'CON.DE',\n",
    "    \"Covestro\": '1COV.DE',\n",
    "    \"Daimler Truck\":'DTG.DE',\n",
    "    \"Delivery Hero\": 'DHER.DE',\n",
    "     \"Deutsche Börse\":'DB1.DE',\n",
    "    \"Deutsche Bank\":\"DBK.DE\",\n",
    " \"Deutsche Post\": 'DHL.DE',\n",
    " \"Deutsche Telekom\":'DTE.DE',\n",
    " \"E.ON\":'EOAN.DE',\n",
    "     \"Fresenius\": \"FRE.DE\",\n",
    "    \"Fresenius Medical Care\":'FME.DE',\n",
    " \"Hannover Rück\":'HNR1.DE',\n",
    " \"HeidelbergCement\": 'HEI.DE',\n",
    "    \"Hello Fresh\": 'HFG.DE',\n",
    "     \"Henkel\":'HEN3.DE',\n",
    "    \"Infineon\": 'IFX.DE',\n",
    "\"Mercedes Benz\": \"MBG.DE\",\n",
    "    \"Merck\": 'MRK.DE',\n",
    " \"MTU Aero Engines\":'MTX.DE',\n",
    " \"Münchner Rück\":'MUV2.DE',\n",
    "     \"Porsche\":'P911.DE',\n",
    "     \"Puma\":'PUM.DE',\n",
    "     \"QIAGEN\":'QIA.DE',\n",
    "    \"RWE\": 'RWE.DE',\n",
    "     \"SAP\":'SAP.DE',\n",
    " \"Sartorius\":'SRT3.DE',\n",
    "    \"Siemens\": 'SIE.DE',\n",
    "    \"Siemens Healthineers\": 'SHL.DE',\n",
    "    \"Symrise\":'SY1.DE',\n",
    "    \"Volkswagen\":'VOW3.DE',\n",
    "    \"Vonovia\": 'VNA.DE',\n",
    " \"Zalando\":'ZAL.DE',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea441521-012e-46a7-8474-957263e9f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_urls=[]\n",
    "#now we go through all the ticker stock ids and create urls\n",
    "for ticker in full_ticker_dict.values():\n",
    "    query_urls.append(\"https://query1.finance.yahoo.com/v8/finance/chart/\"+ticker+\"?symbol=\"+ticker+\"&period1=0&period2=9999999999&interval=1d&includePrePost=true&events=div%2Csplit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a62f7774-a9ca-4434-aff8-b822fea6a26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTX.DEBAYN.DE\n",
      "ZAL.DE\n",
      "ALV.DE\n",
      "MBG.DE\n",
      "SHL.DE\n",
      "FRE.DE\n",
      "BAS.DE\n",
      "1COV.DE\n",
      "P911.DE\n",
      "BEI.DE\n",
      "ADS.DE\n",
      "\n",
      "MRK.DE\n",
      "VOW3.DE\n",
      "DTE.DE\n",
      "HEN3.DE\n",
      "SY1.DE\n",
      "DBK.DE\n",
      "SAP.DE\n",
      "<<<  Historical data of SAP.DE already exists, Updating data...\n",
      "CON.DE\n",
      "HFG.DE\n",
      "<<<  Historical data of CON.DE already exists, Updating data...\n",
      "DB1.DE\n",
      "<<<  Historical data of ALV.DE already exists, Updating data...\n",
      "RWE.DE\n",
      "DTG.DE\n",
      "<<<  Historical data of MBG.DE already exists, Updating data...\n",
      "<<<  Historical data of BEI.DE already exists, Updating data...\n",
      "<<<  Historical data of FRE.DE already exists, Updating data...\n",
      "<<<  Historical data of BAS.DE already exists, Updating data...\n",
      "<<<  Historical data of VOW3.DE already exists, Updating data...\n",
      "IFX.DE\n",
      "BNR.DE\n",
      "SRT3.DE\n",
      "<<<  Historical data of BNR.DE already exists, Updating data...\n",
      "VNA.DE\n",
      "EOAN.DE\n",
      "<<<  Historical data of VNA.DE already exists, Updating data...\n",
      "AIR.PA\n",
      "BMW.DE\n",
      "<<<  Historical data of BMW.DE already exists, Updating data...\n",
      "<<<  Historical data of HFG.DE already exists, Updating data...\n",
      "<<<  Historical data of 1COV.DE already exists, Updating data...\n",
      "<<<  Historical data of RWE.DE already exists, Updating data...\n",
      "<<<  Historical data of HEN3.DE already exists, Updating data...\n",
      "<<<  Historical data of ZAL.DE already exists, Updating data...\n",
      "<<<  Historical data of DTG.DE already exists, Updating data...\n",
      "<<<  Historical data of ADS.DE already exists, Updating data...\n",
      "<<<  Historical data of DBK.DE already exists, Updating data...\n",
      "<<<  Historical data of SHL.DE already exists, Updating data...\n",
      "<<<  Historical data of IFX.DE already exists, Updating data...\n",
      "DHER.DE\n",
      "<<<  Historical data of SRT3.DE already exists, Updating data...\n",
      "DHL.DE\n",
      "HEI.DE\n",
      "<<<  Historical data of DHL.DE already exists, Updating data...\n",
      "<<<  Historical data of AIR.PA already exists, Updating data...\n",
      "HNR1.DE\n",
      "<<<  Historical data of HNR1.DE already exists, Updating data...\n",
      "PUM.DE\n",
      "MUV2.DE\n",
      "<<<  Historical data of DB1.DE already exists, Updating data...\n",
      "<<<  Historical data of DTE.DE already exists, Updating data...\n",
      "<<<  Historical data of SY1.DE already exists, Updating data...\n",
      "<<<  Historical data of P911.DE already exists, Updating data...\n",
      "QIA.DE\n",
      "<<<  Historical data of HEI.DE already exists, Updating data...\n",
      "SIE.DE\n",
      "<<<  Historical data of MTX.DE already exists, Updating data...\n",
      "<<<  Historical data of PUM.DE already exists, Updating data...\n",
      "<<<  Historical data of BAYN.DE already exists, Updating data...\n",
      "<<<  Historical data of MRK.DE already exists, Updating data...\n",
      "<<<  Historical data of DHER.DE already exists, Updating data...\n",
      "<<<  Historical data of QIA.DE already exists, Updating data...\n",
      "<<<  Historical data of MUV2.DE already exists, Updating data...\n",
      "FME.DE\n",
      "<<<  Historical data of EOAN.DE already exists, Updating data...\n",
      "<<<  Historical data of FME.DE already exists, Updating data...\n",
      "<<<  Historical data of SIE.DE already exists, Updating data...\n",
      ">>>  Historical data of DTG.DE saved\n",
      ">>>  Historical data of 1COV.DE saved\n",
      ">>>  Historical data of HFG.DE saved\n",
      ">>>  Historical data of VNA.DE saved\n",
      ">>>  Historical data of SHL.DE saved\n",
      ">>>  Historical data of ZAL.DE saved\n",
      ">>>  Historical data of BNR.DE saved\n",
      ">>>  Historical data of DHER.DE saved\n",
      ">>>  Historical data of P911.DE saved\n",
      ">>>  Historical data of MTX.DE saved\n",
      ">>>  Historical data of HEN3.DE saved>>>  Historical data of AIR.PA saved\n",
      "\n",
      ">>>  Historical data of SY1.DE saved\n",
      ">>>  Historical data of DHL.DE saved\n",
      ">>>  Historical data of DB1.DE saved\n",
      ">>>  Historical data of VOW3.DE saved\n",
      ">>>  Historical data of EOAN.DE saved\n",
      ">>>  Historical data of FRE.DE saved\n",
      ">>>  Historical data of HEI.DE saved\n",
      ">>>  Historical data of HNR1.DE saved\n",
      ">>>  Historical data of PUM.DE saved\n",
      ">>>  Historical data of SRT3.DE saved\n",
      ">>>  Historical data of BEI.DE saved\n",
      ">>>  Historical data of SAP.DE saved\n",
      ">>>  Historical data of QIA.DE saved\n",
      ">>>  Historical data of BAS.DE saved\n",
      ">>>  Historical data of RWE.DE saved\n",
      ">>>  Historical data of MRK.DE saved\n",
      ">>>  Historical data of DTE.DE saved\n",
      ">>>  Historical data of MBG.DE saved\n",
      ">>>  Historical data of MUV2.DE saved\n",
      ">>>  Historical data of DBK.DE saved\n",
      ">>>  Historical data of ADS.DE saved\n",
      ">>>  Historical data of SIE.DE saved\n",
      ">>>  Historical data of ALV.DE saved\n",
      ">>>  Historical data of BMW.DE saved\n",
      ">>>  Historical data of IFX.DE saved\n",
      ">>>  Historical data of FME.DE saved\n",
      ">>>  Historical data of BAYN.DE saved\n",
      ">>>  Historical data of CON.DE saved\n",
      "All downloads completed !\n"
     ]
    }
   ],
   "source": [
    "#and then we go through all urls in a pool process\n",
    "with Pool(processes=len(query_urls)) as pool:\n",
    "    pool.starmap(get_historic_price, zip(query_urls, itertools.repeat(json_path), itertools.repeat(csv_path)))\n",
    "print(\"All downloads completed !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ed5e05f-715f-4ea8-8cf7-64e513e10221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>shortener</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adidas</td>\n",
       "      <td>ADS.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Airbus</td>\n",
       "      <td>AIR.PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allianz</td>\n",
       "      <td>ALV.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BASF</td>\n",
       "      <td>BAS.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bayer</td>\n",
       "      <td>BAYN.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Beiersdorf</td>\n",
       "      <td>BEI.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BMW</td>\n",
       "      <td>BMW.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Brenntag</td>\n",
       "      <td>BNR.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Continental</td>\n",
       "      <td>CON.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Covestro</td>\n",
       "      <td>1COV.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Daimler Truck</td>\n",
       "      <td>DTG.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Delivery Hero</td>\n",
       "      <td>DHER.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Deutsche Börse</td>\n",
       "      <td>DB1.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>DBK.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Deutsche Post</td>\n",
       "      <td>DHL.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Deutsche Telekom</td>\n",
       "      <td>DTE.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E.ON</td>\n",
       "      <td>EOAN.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Fresenius</td>\n",
       "      <td>FRE.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fresenius Medical Care</td>\n",
       "      <td>FME.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Hannover Rück</td>\n",
       "      <td>HNR1.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HeidelbergCement</td>\n",
       "      <td>HEI.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Hello Fresh</td>\n",
       "      <td>HFG.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Henkel</td>\n",
       "      <td>HEN3.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Infineon</td>\n",
       "      <td>IFX.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mercedes Benz</td>\n",
       "      <td>MBG.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Merck</td>\n",
       "      <td>MRK.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MTU Aero Engines</td>\n",
       "      <td>MTX.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Münchner Rück</td>\n",
       "      <td>MUV2.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Porsche</td>\n",
       "      <td>P911.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Puma</td>\n",
       "      <td>PUM.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>QIAGEN</td>\n",
       "      <td>QIA.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RWE</td>\n",
       "      <td>RWE.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SAP</td>\n",
       "      <td>SAP.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Sartorius</td>\n",
       "      <td>SRT3.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Siemens</td>\n",
       "      <td>SIE.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Siemens Healthineers</td>\n",
       "      <td>SHL.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Symrise</td>\n",
       "      <td>SY1.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>VOW3.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Vonovia</td>\n",
       "      <td>VNA.DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Zalando</td>\n",
       "      <td>ZAL.DE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name shortener\n",
       "0                   Adidas    ADS.DE\n",
       "1                   Airbus    AIR.PA\n",
       "2                  Allianz    ALV.DE\n",
       "3                     BASF    BAS.DE\n",
       "4                    Bayer   BAYN.DE\n",
       "5               Beiersdorf    BEI.DE\n",
       "6                      BMW    BMW.DE\n",
       "7                 Brenntag    BNR.DE\n",
       "8              Continental    CON.DE\n",
       "9                 Covestro   1COV.DE\n",
       "10           Daimler Truck    DTG.DE\n",
       "11           Delivery Hero   DHER.DE\n",
       "12          Deutsche Börse    DB1.DE\n",
       "13           Deutsche Bank    DBK.DE\n",
       "14           Deutsche Post    DHL.DE\n",
       "15        Deutsche Telekom    DTE.DE\n",
       "16                    E.ON   EOAN.DE\n",
       "17               Fresenius    FRE.DE\n",
       "18  Fresenius Medical Care    FME.DE\n",
       "19           Hannover Rück   HNR1.DE\n",
       "20        HeidelbergCement    HEI.DE\n",
       "21             Hello Fresh    HFG.DE\n",
       "22                  Henkel   HEN3.DE\n",
       "23                Infineon    IFX.DE\n",
       "24           Mercedes Benz    MBG.DE\n",
       "25                   Merck    MRK.DE\n",
       "26        MTU Aero Engines    MTX.DE\n",
       "27           Münchner Rück   MUV2.DE\n",
       "28                 Porsche   P911.DE\n",
       "29                    Puma    PUM.DE\n",
       "30                  QIAGEN    QIA.DE\n",
       "31                     RWE    RWE.DE\n",
       "32                     SAP    SAP.DE\n",
       "33               Sartorius   SRT3.DE\n",
       "34                 Siemens    SIE.DE\n",
       "35    Siemens Healthineers    SHL.DE\n",
       "36                 Symrise    SY1.DE\n",
       "37              Volkswagen   VOW3.DE\n",
       "38                 Vonovia    VNA.DE\n",
       "39                 Zalando    ZAL.DE"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we lastly create a translate df to write from the stock id the entire name of the stock\n",
    "df_translate=pd.DataFrame(full_ticker_dict,index=[0]).T.reset_index()\n",
    "df_translate.columns=[\"name\",\"shortener\"]\n",
    "df_translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c61457e7-a297-488c-9d19-01ba202d76f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_translate.to_csv(\"../data/translate.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1879f70-ab92-42f0-96c5-ed2021c67b89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PUM.DE'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this proves it has worked\n",
    "shortener_name=df_translate[df_translate[\"name\"]==\"Puma\"].shortener.values[0]\n",
    "pd.read_csv(\"../historic_data/csv/\"+shortener_name+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
